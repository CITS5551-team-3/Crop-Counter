{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import geopandas as gpd\n",
    "import rasterio.mask\n",
    "import fiona\n",
    "import os\n",
    "import numpy as np\n",
    "import shapefile\n",
    "import rasterstats\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import time\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast, Optional\n",
    "\n",
    "# Importing necessary programs from the libraries\n",
    "from rasterio.plot import show\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.crs import CRS\n",
    "from rasterio import features\n",
    "from rasterstats import zonal_stats\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "\n",
    "def img_scale(img: np.ndarray) -> np.ndarray:\n",
    "    return (img * 255).astype(np.uint8)\n",
    "\n",
    "def display_image(img: np.ndarray, _: Optional[str] = None):\n",
    "    display(PIL.Image.fromarray(img))\n",
    "\n",
    "def display_contours(img: np.ndarray, contours):\n",
    "    img_with_contours = img.copy()\n",
    "    for contour in contours:\n",
    "        cv2.drawContours(img_with_contours, [contour], 0, (0, 255, 0), 2)\n",
    "    display_image(img_with_contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Test_Images/temp_ndvi.jpg')\n",
    "img_grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "display_image(img_grey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, thresh  = cv2.threshold(img_grey, 10, 255, cv2.THRESH_BINARY)\n",
    "kernel1= np.ones((7,7), np.uint8)\n",
    "kernel2 = np.ones((5,5), np.uint8)\n",
    "\n",
    "eroded = cv2.erode(thresh, kernel1, iterations = 1)\n",
    "dilated = cv2.dilate(eroded, kernel2, iterations = 8)\n",
    "\n",
    "display_image(dilated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edged = cv2.Canny(img_grey, 30, 200)\n",
    "\n",
    "display_image(edged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "col_grey_img = cv2.cvtColor(img_grey, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "print(len(contours))\n",
    "display_contours(col_grey_img, contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_contours = [contour for contour in contours if 80 < cv2.contourArea(contour)]\n",
    "\n",
    "print(len(large_contours))\n",
    "display_contours(col_grey_img, large_contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours2, _ = cv2.findContours(img_grey, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "print(len(contours2))\n",
    "display_contours(col_grey_img, contours2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_contours2 = [contour for contour in contours2 if 200 < cv2.contourArea(contour)]\n",
    "\n",
    "print(len(large_contours2))\n",
    "display_contours(col_grey_img, large_contours2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_line_img(img: np.ndarray, print_img: np.ndarray = cast(np.ndarray, np.copy(col_grey_img)) * 0) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"line, img\"\"\"\n",
    "\n",
    "    # see https://stackoverflow.com/a/45560545/8626693\n",
    "\n",
    "    rho = 1  # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "    threshold = 15  # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 50  # minimum number of pixels making up a line\n",
    "    max_line_gap = 20  # maximum gap in pixels between connectable line segments\n",
    "    line_image = np.copy(print_img)\n",
    "\n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), min_line_length, max_line_gap)\n",
    "\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(line_image, (x1, y1), (x2, y2), (255, 0, 0), 5)\n",
    "    \n",
    "    return lines, line_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines1, line_img1 = gen_line_img(edged, col_grey_img)\n",
    "print(len(lines1))\n",
    "print(sum([len(line) for line in lines1]))\n",
    "display_image(line_img1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
